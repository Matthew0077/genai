{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "190D_rA20ytIt63IrS-JGJlEtdBOM1WvC",
      "authorship_tag": "ABX9TyMUYk0mch0Z+5RV7qgJkTCS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matthew0077/genai/blob/main/61201032e_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "師大 61201032e 心輔碩一\n",
        "\n",
        "#主題一\n",
        "##Chatgpt回答：(prompt：為什麼現在都用diffusion models不用GAN)\n",
        "我自己看完後的理解是\n",
        "\n",
        "# GAN的問題：\n",
        "\n",
        "訓練過程不穩定，過程中容易出現崩潰，就是會生成一堆非常相似的圖片，無法**多樣化**生成結果。在我生成的過程中有遇過，但不多，我生成human的時候有遇到生成一樣的人(是一個黑色皮膚的女性)，還有一些相似度很高的畫，因為我不是美術生，我看每一張都一個樣子。生成的圖片***缺乏多樣性***，可能是因為都在做同一件事/是指令?\n",
        "\n",
        "難以調整：GAN的***參數調整麻煩***，要**多次**生成才可以確保模型的穩定性(後面是我猜的)因為我一直生成畫作時都是同一樣畫的很醜?很藝術。它可能一個很穩定的狀態，就是醜。\n",
        "\n",
        "解析度限制：可以生成高質量的圖片(在***低***解析度)，但生成更***高***解析度的圖片就會很模糊，在生成***非常精細***的細節圖片時，會出現***瑕疵***。\n",
        "\n",
        "很難控制生成結果：生成圖片時，控制生成的內容非常困難。就像是HUMAN的跟貓的都是沒有可以選的，但畫貓的會比較好一點點，可以根據自己畫的形狀生成，無法精確的生成圖片。\n",
        "\n",
        "較高的計算要求：由於GAN需要大量的訓練，所以它的計算成本較高。在生成高解析度圖片時，訓練時間和硬體要求非常大。\n",
        "\n",
        "\n",
        "# 擴散模型的優點：\n",
        "\n",
        "穩定的訓練過程：通過逐步去噪的過程生成圖片，訓練過程**比GAN穩定**。優勢在於它們**不依賴**對抗學習，直接從數據抽取學習樣本。\n",
        "\n",
        "無模式崩潰問題：生成過程是基於去噪的過程，在生成時能夠產生更***多樣化***和***高品質***的圖片，圖片的細節也是準確的，並且圖片的紋理和顏色是自然和正常的。\n",
        "\n",
        "生成過程的直觀性和可控性強：基於文本的生成模型（如Stable Diffusion），用戶提供具體的**文本描述**，模型根據描述生成高品質的圖片。這種可控性令它可以在很多場景中應用。\n",
        "\n",
        "計算時間較長：擴散模型的生成過程是逐步進行的（由噪音逐步去噪），這使得生成圖片的過程相對較慢，通常需要更多的計算資源。雖然它的訓練和生成過程也很高效，但相比GAN，它的生成過程需要更多的步驟。\n",
        "\n",
        "我的結論就是diffusion models 可以依用戶的描述去做事，會更有效率。雖然計算資源會比較多，但在現在的電腦科技下也不算一個很大的問題。\n",
        "\n",
        "#介紹使用的GAN生成網站\n",
        "\n",
        "\n",
        "1.   [This Person Does Not Exist](https://thispersondoesnotexist.com/)\n",
        "\n",
        "簡介：這個網站是基於 StyleGAN 的生成對抗網絡（GAN），專門用來生成虛構的人的臉。每次刷新，都會生成一個全新的虛構人物圖片。這些圖片看起來很真實，完全是無法與真實人物照片區分開來。但是我生成了一個黑人女性是重複的。\n",
        "\n",
        "\n",
        "\n",
        "2.   [Artbreeder](https://https://www.artbreeder.com/tools/paintings)\n",
        "簡介：基於BigGAN和StyleGAN，允許用戶調整生成的圖像特徵，創建藝術作品。用戶調整和混合不同的圖像特徵，創造出全新的藝術作品。用戶可以通過滑動條來改變圖像的各種屬性（如年齡、表情、顏色）。\n",
        "很好用就是圖片的畫質不是很好。\n",
        "\n",
        "\n",
        "3.   [Pix2Pix](https://affinelayer.com/pixsrv/)\n",
        "簡介：Pix2Pix是一個基於 GAN 的圖像轉換模型，它可以將草圖、線條或低解析度的圖像轉換為逼真的照片。例如，你可以手繪一個簡單的圖像，然後使用Pix2Pix生成一個細緻的實景照片。這個網站展示了 Pix2Pix 的能力，能夠執行類似的圖像到圖像的轉換任務。\n",
        "\n",
        "\n",
        "#介紹使用的diffusion models生成網站\n",
        "1.   [DALL·E2 by OpenAI](https://openai.com/index/dall-e-2/)\n",
        "\n",
        "簡介：DALL·E2 是由 OpenAI 開發的生成模型，根據用戶的文本描述生成高質量的圖像。這個模型使用擴散過程來生成圖像，用戶只需提供簡單的文字描述，模型就能生成相應的圖片。\n",
        "\n",
        "2.   [Stable Diffusion](https://stablediffusionweb.com/zh-tw)\n",
        "\n",
        "簡介：Stable Diffusion 是一個開源的文本到圖像生成模型，它利用擴散模型來生成高質量的圖片。用戶輸入描述性的文本，並能生成對應的圖像。該模型在各種創意生成任務中表現出色，並因其開源性使它非常受歡迎。\n",
        "\n",
        "3.   [Deep Dream Generator](https://deepdreamgenerator.com/)\n",
        "\n",
        "簡介：Deep Dream Generator 是一個使用深度學習和擴散模型來創造藝術風格圖片的網站。用戶輸入描述性的文本或上傳自己的圖片，選擇不同的風格進行轉換。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VpPtbza1vUdk"
      }
    }
  ]
}